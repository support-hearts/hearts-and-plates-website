cat > robots.txt << 'EOF'
User-agent: *
Allow: /

# Disallow admin or sensitive areas (if any)
Disallow: /admin/
Disallow: /config/
Disallow: /.git/

# Sitemap location
Sitemap: https://heartsandplates.com/sitemap.xml

# Crawl delay (optional)
Crawl-delay: 1
EOF